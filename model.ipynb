{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "csv_file = 'ad_click_dataset.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# defining helper function to fill empty values\n",
    "def fill_vals_weighted(column_name):\n",
    "    entries = data[column_name].dropna().unique()\n",
    "    occurences = data[column_name].value_counts()\n",
    "    \n",
    "    return random.choices(entries, weights=[occurences.get(entry) for entry in entries])[0]\n",
    "\n",
    "def fill_vals(column_name):\n",
    "    entries = data[column_name].dropna().unique()\n",
    "    \n",
    "    return random.choices(entries)[0]\n",
    "        \n",
    "# deal with missing values\n",
    "cols_to_fill = ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']\n",
    "for col in cols_to_fill:\n",
    "    data[col] = data[col].fillna(fill_vals_weighted(col))\n",
    "    \n",
    "mean_age = data['age'].mean()\n",
    "data['age'] = data['age'].fillna(mean_age)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing to create training and testing sets\n",
    "features = data.drop(['id', 'click', 'full_name'], axis=1)\n",
    "encoded_features = pd.get_dummies(features, columns=['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day'])\n",
    "target = data['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_features, target, test_size=0.1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    \n",
    "    Dense(256),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(.25),\n",
    "    \n",
    "    Dense(256),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(.25),\n",
    "    \n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(.25),\n",
    "    \n",
    "    Dense(64),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(.25),\n",
    "    \n",
    "    Dense(32),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 - 2s - 7ms/step - accuracy: 0.5982 - loss: 0.6881 - val_accuracy: 0.6028 - val_loss: 0.6603\n",
      "Epoch 2/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6422 - loss: 0.6557 - val_accuracy: 0.6622 - val_loss: 0.6418\n",
      "Epoch 3/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6410 - loss: 0.6523 - val_accuracy: 0.6617 - val_loss: 0.6341\n",
      "Epoch 4/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6429 - loss: 0.6508 - val_accuracy: 0.6617 - val_loss: 0.6407\n",
      "Epoch 5/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6478 - loss: 0.6504 - val_accuracy: 0.6617 - val_loss: 0.6334\n",
      "Epoch 6/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6460 - loss: 0.6468 - val_accuracy: 0.6617 - val_loss: 0.6374\n",
      "Epoch 7/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6483 - loss: 0.6462 - val_accuracy: 0.6600 - val_loss: 0.6332\n",
      "Epoch 8/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6501 - loss: 0.6446 - val_accuracy: 0.6606 - val_loss: 0.6424\n",
      "Epoch 9/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6481 - loss: 0.6456 - val_accuracy: 0.6622 - val_loss: 0.6359\n",
      "Epoch 10/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6511 - loss: 0.6432 - val_accuracy: 0.6617 - val_loss: 0.6301\n",
      "Epoch 11/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6465 - loss: 0.6448 - val_accuracy: 0.6617 - val_loss: 0.6290\n",
      "Epoch 12/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6483 - loss: 0.6430 - val_accuracy: 0.6617 - val_loss: 0.6342\n",
      "Epoch 13/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6482 - loss: 0.6429 - val_accuracy: 0.6617 - val_loss: 0.6310\n",
      "Epoch 14/150\n",
      "225/225 - 0s - 1ms/step - accuracy: 0.6490 - loss: 0.6415 - val_accuracy: 0.6594 - val_loss: 0.6355\n",
      "Epoch 15/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6474 - loss: 0.6405 - val_accuracy: 0.6633 - val_loss: 0.6321\n",
      "Epoch 16/150\n",
      "225/225 - 0s - 2ms/step - accuracy: 0.6461 - loss: 0.6414 - val_accuracy: 0.6572 - val_loss: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x36c5b9310>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# initial_learning_rate = .001\n",
    "# lr_schedule = ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=.001)\n",
    "\n",
    "loss = BinaryCrossentropy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=.2,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6393 - loss: 0.6531\n",
      "Test accuracy; 0.636, Test loss: 0.654\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test accuracy; {round(test_accuracy, 3)}, Test loss: {round(test_loss, 3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
